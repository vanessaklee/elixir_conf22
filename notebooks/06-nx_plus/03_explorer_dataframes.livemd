# Explorer: DataFrame

```elixir
Mix.install([
  {:explorer, "~> 0.2.0"}
])
```

## DataFrames

A `DataFrame` is really just a collection of `Series` of the same size. Which is why you can create a `DataFrame` from a `Keyword` list.

```elixir
alias Explorer.DataFrame

df = DataFrame.new(a: [1, 2, 3], b: ["a", "b", "c"])
```

Similarly to `Series`, the `Inspect` implementation prints some info at the top and to the left. At the top we see the shape of the dataframe (rows and columns) and then for each column we see the name, dtype, and first five values. We can see a bit more from that built-in dataset we loaded in earlier.

```elixir
df
```

You can directly access the details of a DataFrame:

```elixir
df = DataFrame.new(a: [1, 2, 3], b: ["a", "b", "c"])

IO.inspect(DataFrame.names(df), label: "Names")
IO.inspect(DataFrame.dtypes(df), label: "Datatypes")
IO.inspect(DataFrame.shape(df), label: "Shape")
IO.inspect(DataFrame.n_rows(df), label: "# of rows")
IO.inspect(DataFrame.n_columns(df), label: "# of columns")
```

Plus the head and tail.

```elixir
IO.inspect(DataFrame.head(df), label: "Head")
IO.inspect(DataFrame.tail(df, 2), label: "Tail")
```

## Dataframe Select

TODO consider moving this section later, after covering the the Select options

This Fraud Detection dataset contains transactions made by credit cards in September 2013 by European cardholders. The transactions occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.

It contains only numerical input variables which are the result of a PCA transformation. Features V1, V2, â€¦ V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-sensitive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.

```elixir
# The Fraud Detection data set
fraud_df = Explorer.DataFrame.from_csv!("data/creditcard.csv", dtypes: [{"Time", :float}])

# The data set has these headers
# ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',
# 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',
# 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',
# 'Class']

IO.inspect(
  DataFrame.select(fraud_df, ["Time", "V1", "Class"]),
  label: "Values for Time, V1, and Class"
)

IO.inspect(
  DataFrame.select(fraud_df, &String.contains?(&1, "V1")),
  label: "Values that start with 'V1'"
)

IO.inspect(
  Explorer.DataFrame.select(fraud_df, &(&1 == "Class"), :keep),
  label: "Keep only the Class column"
)
```

```elixir
# Filter
# Use callbacks on the dataframe to generate boolean mask series 
# of the same size as the dataframe. Here we filter for only time values
# greater than or equal to a set value.
IO.inspect(
  DataFrame.filter(fraud_df, &Series.greater_equal(&1["Time"], 172_786.0)),
  label: "Filter for Time greater than or equal to 172786.0"
)

# You can pipe filters
IO.inspect(
  DataFrame.filter(fraud_df, &Series.greater_equal(&1["Time"], 172_786.0))
  |> DataFrame.filter(&Series.less(&1["V1"], -10.0))
  |> DataFrame.select(&(&1 == "Amount"), :keep),
  label: "Piped filters"
)
```

### Mutate

Add columns or change existing ones. You can pass in new columns as keyword arguments. It also works to transform existing columns. You may not always want to use keyword arguments. Given that column names are String.t(), it may make more sense to use a map.

```elixir
# Mutate the Class column from integer to float
DataFrame.mutate(fraud_df,
  Class: &Series.cast(&1["Class"], :float)
)
|> DataFrame.select(&(&1 == "Class"), :keep)
```

### Sampling

Random samples can give us a percent or a specific number of samples, with or without replacement, and the function is seedable.

```elixir
DataFrame.sample(fraud_df, 0.000014)
|> DataFrame.select(&(&1 in ["Time", "V12", "Class"]), :keep)
```

```elixir
DataFrame.pull(fraud_df, "Amount")
```

```elixir
DataFrame.take(fraud_df, [1, 50, 100])
|> DataFrame.select(&(&1 in ["Time", "V20", "Class"]), :keep)
```

```elixir
DataFrame.slice(fraud_df, 1500, 5)
|> DataFrame.select(&(&1 in ["Time", "V15", "Class"]), :keep)
```

```elixir
Explorer.Datasets.fossil_fuels()
|> Explorer.DataFrame.group_by("year")
|> Explorer.DataFrame.summarise(total: [:max, :min], country: [:n_unique])
```

```elixir
# Group by Class and summarize the min/max values
fraud_df
|> Explorer.DataFrame.group_by("Class")
|> Explorer.DataFrame.summarise(Time: [:max, :min])
```

### Select

Let's jump right into it. We can select columns pretty simply.

```elixir
DataFrame.select(df, ["year", "country"])
```

But Elixir gives us some superpowers. In R there's [`tidy-select`](https://dplyr.tidyverse.org/reference/dplyr_tidy_select.html). I don't think we need that in Elixir. Anywhere in `Explorer` where you need to pass a list of column names, you can also execute a filtering callback on the column names. It's just an anonymous function passed to `df |> DataFrame.names() |> Enum.filter(callback_here)`.

```elixir
DataFrame.select(df, &String.ends_with?(&1, "fuel"))
```

Want all but some columns? `DataFrame.select/3` takes `:keep` or `:drop` as the last arg. It just defaults to `:keep`.

```elixir
DataFrame.select(df, &String.ends_with?(&1, "fuel"), :drop)
```

### Filter

The next verb we'll look at is `filter`. You can pass in a boolean mask series of the same size as the dataframe, but I find it's more handy to use callbacks on the dataframe to generate those masks.

```elixir
DataFrame.filter(df, &Series.equal(&1["country"], "AFGHANISTAN"))
```

```elixir
filtered_df =
  df
  |> DataFrame.filter(&Series.equal(&1["country"], "ALGERIA"))
  |> DataFrame.filter(&Series.greater(&1["year"], 2012))
```

```elixir
DataFrame.filter(filtered_df, [true, false])
```

Remember those helpful error messages?

```elixir
DataFrame.filter(df, &Series.equal(&1["cuontry"], "AFGHANISTAN"))
```

### Mutate

A common task in data analysis is to add columns or change existing ones. Mutate is a handy verb.

```elixir
DataFrame.mutate(df, new_column: &Series.add(&1["solid_fuel"], &1["cement"]))
```

Did you catch that? You can pass in new columns as keyword arguments. It also works to transform existing columns.

```elixir
DataFrame.mutate(df,
  gas_fuel: &Series.cast(&1["gas_fuel"], :float),
  gas_and_liquid_fuel: &Series.add(&1["gas_fuel"], &1["liquid_fuel"])
)
```

`DataFrame.mutate/2` is flexible though. You may not always want to use keyword arguments. Given that column names are `String.t()`, it may make more sense to use a map.

```elixir
DataFrame.mutate(df, %{"gas_fuel" => &Series.subtract(&1["gas_fuel"], 10)})
```

`DataFrame.transmute/2`, which is `DataFrame.mutate/2` that only retains the specified columns, is forthcoming.

### Arrange

Sorting the dataframe is pretty straightforward.

```elixir
DataFrame.arrange(df, "year")
```

But it comes with some tricks up its sleeve.

```elixir
DataFrame.arrange(df, asc: "total", desc: "year")
```

Sort operations happen left to right. And keyword list args permit specifying the direction.

### Distinct

Okay, as expected here too. Very straightforward.

```elixir
DataFrame.distinct(df, columns: ["year", "country"])
```

You can specify whether to keep the other columns as well.

```elixir
DataFrame.distinct(df, columns: ["country"], keep_all?: true)
```

### Rename

Rename can take either a list of new names or a callback that is passed to `Enum.map/2` against the names. You can also use a map or keyword args to rename specific columns.

```elixir
DataFrame.rename(df, year: "year_test")
```

```elixir
DataFrame.rename_with(df, &(&1 <> "_test"))
```

### Dummies

This is fun! We can get dummy variables for unique values.

```elixir
DataFrame.dummies(df, ["year"])
```

```elixir
DataFrame.dummies(df, ["country"])
```

### Sampling

Random samples can give us a percent or a specific number of samples, with or without replacement, and the function is seedable.

```elixir
DataFrame.sample(df, 10)
```

```elixir
DataFrame.sample(df, 0.4)
```

Trying for those helpful error messages again.

```elixir
DataFrame.sample(df, 10000)
```

```elixir
DataFrame.sample(df, 10000, replacement: true)
```

### Pull/slice/take

Slicing and dicing can be done with the `Access` protocol or with explicit pull/slice/take functions.

```elixir
df["year"]
```

```elixir
DataFrame.pull(df, "year")
```

```elixir
df[["year", "country"]]
```

```elixir
DataFrame.take(df, [1, 20, 50])
```

Negative offsets work for slice!

```elixir
DataFrame.slice(df, -10, 5)
```

```elixir
DataFrame.slice(df, 10, 5)
```

### Pivot

We can `pivot_longer/3` and `pivot_wider/4`. These are inspired by [tidyr](https://tidyr.tidyverse.org/articles/pivot.html).

There are some shortcomings in `pivot_wider/4` related to `polars`. The `values_from` column must be a numeric type.

```elixir
DataFrame.pivot_longer(df, ["year", "country"], value_columns: &String.ends_with?(&1, "fuel"))
```

```elixir
DataFrame.pivot_wider(df, "country", "total", id_columns: ["year"])
```

Let's make those names look nicer!

```elixir
tidy_names = fn name ->
  name
  |> String.downcase()
  |> String.replace(~r/\s/, " ")
  |> String.replace(~r/[^A-Za-z\s]/, "")
  |> String.replace(" ", "_")
end

df
|> DataFrame.pivot_wider("country", "total", id_columns: ["year"])
|> DataFrame.rename_with(tidy_names)
```

### Joins

Joining is *fast* and easy. You can specify the columns to join on and how to join. Polars even supports cartesian (cross) joins, so `Explorer` does too.

```elixir
df1 = DataFrame.select(df, ["year", "country", "total"])
df2 = DataFrame.select(df, ["year", "country", "cement"])
DataFrame.join(df1, df2)
```

```elixir
df3 = df |> DataFrame.select(["year", "cement"]) |> DataFrame.slice(0, 500)
DataFrame.join(df1, df3, how: :left)
```

### Grouping

`Explorer` supports groupby operations. They're limited based on what's possible in Polars, but they do most of what you need to do.

```elixir
grouped = DataFrame.group_by(df, ["country"])
```

Notice that the `Inspect` call now shows `groups` as well as `rows` and `columns`. You can, of course, get them explicitly.

```elixir
DataFrame.groups(grouped)
```

And you can ungroup explicitly.

```elixir
DataFrame.ungroup(grouped)
```

But what we care about the most is aggregating! Let's see which country has the max `per_capita` value.

```elixir
grouped |> DataFrame.summarise(per_capita: [:max]) |> DataFrame.arrange(desc: :per_capita_max)
```

Qatar it is. You can use the following aggregations:

* `:min` - Take the minimum value within the group. See `Explorer.Series.min/1`.
* `:max` - Take the maximum value within the group. See `Explorer.Series.max/1`.
* `:sum` - Take the sum of the series within the group. See `Explorer.Series.sum/1`.
* `:mean` - Take the mean of the series within the group. See `Explorer.Series.mean/1`.
* `:median` - Take the median of the series within the group. See `Explorer.Series.median/1`.
* `:first` - Take the first value within the group. See `Explorer.Series.first/1`.
* `:last` - Take the last value within the group. See `Explorer.Series.last/1`.
* `:count` - Count the number of rows per group.
* `:n_unique` - Count the number of unique rows per group.

The API is similar to `mutate`: you can use keyword args or a map and specify aggregations to use.

```elixir
grouped |> DataFrame.summarise(per_capita: [:max, :min], total: [:min])
```

Speaking of `mutate`, it's 'group-aware'. As are `arrange`, `distinct`, and `n_rows`.

```elixir
DataFrame.arrange(grouped, desc: :total)
```
